{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practicing Text Generation one more time.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN5rQEkPbwJZnduCIppo+Vw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumanyurosha/tensorflow-specialization/blob/master/Practice/Practicing_Text_Generation_one_more_time.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOIjYBM3xiUK"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSM5uToZ0rJk"
      },
      "source": [
        "# **Downloading the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIfWwNsTynZz",
        "outputId": "6bede185-0826-4da9-8e64-a17b3114f7a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "shakespeare_url = \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\"\n",
        "filepath = keras.utils.get_file(\"shakespeare\", shakespeare_url)\n",
        "\n",
        "with open(filepath, \"r\") as f:\n",
        "    text_data = f.read()\n",
        "\n",
        "print(\"The size of Dataset is :{}\".format(len(text_data)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of Dataset is :1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxYQ_sov0vD_"
      },
      "source": [
        "# **Analyzing the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCQV4tBw0IJu",
        "outputId": "a63df8f3-848e-4677-93d1-ee3913ce4c95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(text_data[:250])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOnEUOKXzZJq",
        "outputId": "f99819a5-d3eb-43d7-ecd8-a0586d66514e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab = sorted(set(text_data))\n",
        "print(\"Unique characters in the Dataset are : {}\".format(len(vocab)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique characters in the Dataset are : 65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g91uNYaSzoZ1",
        "outputId": "12e36d86-eec6-47e1-d60d-6dc1847cb465",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for char, i in zip(vocab, range(20)):\n",
        "    print(\"{} : {}\".format(i+1, repr(char)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 : '\\n'\n",
            "2 : ' '\n",
            "3 : '!'\n",
            "4 : '$'\n",
            "5 : '&'\n",
            "6 : \"'\"\n",
            "7 : ','\n",
            "8 : '-'\n",
            "9 : '.'\n",
            "10 : '3'\n",
            "11 : ':'\n",
            "12 : ';'\n",
            "13 : '?'\n",
            "14 : 'A'\n",
            "15 : 'B'\n",
            "16 : 'C'\n",
            "17 : 'D'\n",
            "18 : 'E'\n",
            "19 : 'F'\n",
            "20 : 'G'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQYpjtW403aH"
      },
      "source": [
        "# **Creating a Vocabulary out of the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBfEyE2Vz1S4",
        "outputId": "62d53d1f-4a9c-46cf-dacc-e8b8a6e92341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "char2idx = {char:i for i, char in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "# converting text into a sequence of integers\n",
        "text_as_int = ap.array([char2idx[char] for char in text_data])\n",
        "\n",
        "print(repr(text_data[:13]))\n",
        "print(text_as_int[:13])"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-7107539b0795>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# converting text into a sequence of integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtext_as_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ap' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTJw7_Zv2NfL"
      },
      "source": [
        "# **Setting Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDi_oB152M12"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "batch_size = 32\n",
        "seq_len = 100\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL9HEXXi2glj"
      },
      "source": [
        "# **Creating a Dataset for our Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubjCCvyF22ZJ",
        "outputId": "cdef6e99-cfdb-49f6-9e16-e957cfe19438",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# creating a Dataset with batches equal to sequence length + 1 (+ 1 for target)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "dataset = dataset.batch(seq_len + 1, drop_remainder=True)\n",
        "\n",
        "# shape should be (101, )\n",
        "dataset"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: (101,), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5d0ghBV383Z"
      },
      "source": [
        "# **Creating Input and Target Values for our Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgmUGfKQ2gCH"
      },
      "source": [
        "def seperate_input_target(chunk):\n",
        "    # all except the last\n",
        "    input_text = chunk[:-1]\n",
        "    # all except the first\n",
        "    output_text = chunk[1:]\n",
        "\n",
        "    return input_text, output_text\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7672eiH1lcG",
        "outputId": "d5230f60-355e-48c9-c8cb-51ca7aabefdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset = dataset.map(seperate_input_target)\n",
        "\n",
        "# shape should be (100, ), (100, )\n",
        "dataset"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: ((100,), (100,)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHSi_9sr6OJM"
      },
      "source": [
        "# **Checking what our model will see**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXITpL4v6Jj1",
        "outputId": "65c4a4b1-6cfa-4969-f7bf-e6ec54ff44df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for input, output in dataset.take(1):\n",
        "    print(\"Input : {}\".format(repr(\"\".join([idx2char[char] for char in input]))))\n",
        "    print()\n",
        "    print(\"Output: {}\".format(repr(\"\".join([idx2char[char] for char in output]))))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : 'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "\n",
            "Output: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwYjEa657Sg5"
      },
      "source": [
        "# **Creating batches of our Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZHZJBIB5rWq",
        "outputId": "80459609-d70f-48f4-dca8-e1990b71e0f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "# shape should be (32, 100), (32, 100)\n",
        "dataset"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((32, 100), (32, 100)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cO1Lp0q4l91"
      },
      "source": [
        "# **Creating a Model for our Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hYejVwn4H6T"
      },
      "source": [
        "def build_model(batch_size, rnn_units, vocab_size, embedding_dim):\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Embedding(vocab_size, embedding_dim, \n",
        "                               batch_input_shape=[batch_size,None]),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.LSTM(rnn_units, return_sequences=True),\n",
        "        keras.layers.LSTM(rnn_units, return_sequences=True),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.TimeDistributed(keras.layers.Dense(vocab_size,\n",
        "                                                        activation=\"softmax\"))\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGYYprrr5psr",
        "outputId": "e98c15cf-01c5-48f9-8f01-67b21e4fd73c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = build_model(batch_size=batch_size, \n",
        "                    rnn_units=rnn_units,\n",
        "                    vocab_size=vocab_size,\n",
        "                    embedding_dim=embedding_dim)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"adam\")"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (32, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (32, None, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (32, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "lstm_13 (LSTM)               (32, None, 1024)          8392704   \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (32, None, 1024)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, None, 65)          66625     \n",
            "=================================================================\n",
            "Total params: 13,722,945\n",
            "Trainable params: 13,722,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2QjRQk_8o2p"
      },
      "source": [
        "# **Checking the Model beahviour and Output shape**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmL0R7vb9rpb",
        "outputId": "72011072-8307-4292-a929-053b6c9f3995",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for input, output in dataset.take(1):  \n",
        "    predicted_example = model(input)\n",
        "    print(predicted_example.shape)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 100, 65)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2jD7uXnGQgI",
        "outputId": "c4bd4c6c-d9dd-4cc1-e014-a764faf4dfda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predicted_example[0][0]"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(65,), dtype=float32, numpy=\n",
              "array([3.5938262e-03, 3.0688548e-02, 4.6976193e-04, 5.3626401e-05,\n",
              "       3.4623543e-05, 1.1225550e-03, 5.4782006e-04, 3.0121815e-05,\n",
              "       2.5461137e-03, 2.2743354e-04, 2.1512891e-01, 3.8794577e-04,\n",
              "       8.3608821e-04, 6.8289451e-02, 2.7665282e-03, 8.9873141e-03,\n",
              "       2.9536379e-03, 2.2809071e-02, 5.5330904e-04, 1.5011266e-03,\n",
              "       5.2522095e-03, 6.9116496e-02, 3.6170695e-05, 4.0671337e-04,\n",
              "       4.1097519e-03, 6.5891113e-04, 2.0375688e-05, 2.2689320e-02,\n",
              "       5.0640851e-04, 1.8345378e-04, 1.0770534e-03, 7.1407743e-03,\n",
              "       8.2177348e-02, 3.4019724e-02, 7.1926817e-04, 4.1525549e-04,\n",
              "       2.5272454e-04, 1.3994767e-03, 5.5581291e-04, 2.5084388e-02,\n",
              "       2.9218950e-06, 5.2371621e-03, 3.1635744e-05, 1.4636083e-01,\n",
              "       7.7865716e-06, 2.2307000e-05, 4.5928132e-02, 7.0654839e-02,\n",
              "       3.3628818e-04, 7.0038222e-04, 1.7287569e-04, 6.5381249e-04,\n",
              "       1.7150949e-05, 8.3535679e-02, 1.8570747e-03, 9.1692130e-04,\n",
              "       3.4283064e-06, 2.7011000e-04, 2.1304430e-02, 2.3232559e-03,\n",
              "       9.4295465e-06, 1.9638146e-04, 4.6958785e-06, 8.9820765e-05,\n",
              "       1.3220934e-05], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1djDWGDF82St",
        "outputId": "5503182c-b779-4752-c11f-8be5d170beb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# select a sequence from the batch\n",
        "# here predicted_example[0] has a shape (seq_len, vocab_size)\n",
        "# where row[i, :] contains prob for each word in the vocab for the ith word in the sequence\n",
        "prediction = tf.random.categorical(predicted_example[0], num_samples=1)\n",
        "prediction = tf.squeeze(prediction, axis=-1)\n",
        "prediction"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
              "array([51, 43, 26, 21, 13,  5, 58, 36, 23,  7, 22, 45, 12, 48, 57, 42, 30,\n",
              "       64, 24, 34,  1,  1, 60, 32, 27, 61, 47, 45, 50, 12, 58,  7,  1, 24,\n",
              "       54, 45, 10, 18, 18, 57,  4, 41, 25, 12, 51, 20,  5, 52, 38, 39, 63,\n",
              "        2,  1, 18, 59, 38, 63, 35, 51, 31, 43, 46, 52, 54, 50, 17,  5, 62,\n",
              "       13, 40, 17,  6, 49, 16, 33, 18, 27, 19, 55, 15,  6, 40, 36, 25, 17,\n",
              "       63, 44, 48, 51, 64, 53, 45, 13,  1, 20, 56, 57,  1, 42, 46])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VHQniLbCIAr",
        "outputId": "2c9841de-9f80-4c0d-efb9-52da9a7abaf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# we should expect very random sequence because the model is not trained yet\n",
        "print(repr(\"\".join([idx2char[c] for c in prediction])))"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"meNIA'tXK-Jg?jsdRzLV  vTOwigl?t- Lpg:FFs&cM?mH'nZay! FuZyWmSehnplE'xAbE,kDUFOGqC,bXMEyfjmzogA Hrs dh\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wH7SIjdKZo_"
      },
      "source": [
        "# **Creating a Checkpoint Callback for saving our Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRAuA2gUCtQ-"
      },
      "source": [
        "checkpoint_dir = \"/checkpoints\"\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"{epoch}\")\n",
        "\n",
        "checkpoint_callback = keras.callbacks.ModelCheckpoint(checkpoint_prefix,\n",
        "                                                      save_weights_only=True)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7voTS07yK5yi"
      },
      "source": [
        "# **Training our Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywO8lvAfK4UM",
        "outputId": "3facce97-f034-415c-92bf-1e1b50ee8361",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(dataset, epochs=30, callbacks=[checkpoint_callback], verbose=1)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "345/345 [==============================] - 32s 94ms/step - loss: 2.5473\n",
            "Epoch 2/30\n",
            "345/345 [==============================] - 33s 96ms/step - loss: 1.7319\n",
            "Epoch 3/30\n",
            "345/345 [==============================] - 35s 100ms/step - loss: 1.4993\n",
            "Epoch 4/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 1.3882\n",
            "Epoch 5/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 1.3165\n",
            "Epoch 6/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 1.2583\n",
            "Epoch 7/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 1.2056\n",
            "Epoch 8/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 1.1530\n",
            "Epoch 9/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 1.1004\n",
            "Epoch 10/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 1.0460\n",
            "Epoch 11/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.9909\n",
            "Epoch 12/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.9363\n",
            "Epoch 13/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.8808\n",
            "Epoch 14/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.8271\n",
            "Epoch 15/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.7774\n",
            "Epoch 16/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.7293\n",
            "Epoch 17/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.6837\n",
            "Epoch 18/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.6437\n",
            "Epoch 19/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.6063\n",
            "Epoch 20/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.5715\n",
            "Epoch 21/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.5402\n",
            "Epoch 22/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.5111\n",
            "Epoch 23/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.4889\n",
            "Epoch 24/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.4680\n",
            "Epoch 25/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.4509\n",
            "Epoch 26/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.4342\n",
            "Epoch 27/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.4202\n",
            "Epoch 28/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.4089\n",
            "Epoch 29/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.3990\n",
            "Epoch 30/30\n",
            "345/345 [==============================] - 35s 102ms/step - loss: 0.3894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nI5BrcKLlwb"
      },
      "source": [
        "# **Building a new model with saved weights but different batch size for Text Generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq7QAgRBMMSG",
        "outputId": "37d70d78-d2f3-4521-cc43-f9e337adfe1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/checkpoints/30'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNWcOKg4LlMB",
        "outputId": "fb7b4084-38f6-4a8e-b71c-4913fc34c019",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = build_model(batch_size=1, vocab_size=vocab_size,\n",
        "                    embedding_dim=embedding_dim, rnn_units=rnn_units)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "# here the batch_size should be 1\n",
        "model.summary()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (1, None, 256)            16640     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (1, None, 256)            0         \n",
            "_________________________________________________________________\n",
            "lstm_14 (LSTM)               (1, None, 1024)           5246976   \n",
            "_________________________________________________________________\n",
            "lstm_15 (LSTM)               (1, None, 1024)           8392704   \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (1, None, 1024)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, None, 65)          66625     \n",
            "=================================================================\n",
            "Total params: 13,722,945\n",
            "Trainable params: 13,722,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQzmxUcrLFbS"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "\n",
        "    text_length = 1000\n",
        "    text_generated = []\n",
        "\n",
        "    input_sequence = np.array([char2idx[c] for c in start_string])\n",
        "    input_sequence = tf.expand_dims(input_sequence, 0)\n",
        "\n",
        "    for i in range(text_length):\n",
        "        prediction = model(input_sequence)\n",
        "\n",
        "        prediction = tf.squeeze(prediction, 0)\n",
        "        prediction_id = tf.random.categorical(prediction, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        input_sequence = tf.expand_dims([prediction_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[prediction_id])\n",
        "\n",
        "    return start_string + \"\".join(text_generated)\n"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPi-1BnBPSuy",
        "outputId": "f300a18c-ba4c-473f-9c31-a744d804bedb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(generate_text(model, \"Romeo:\"))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Romeo:VHuR\n",
            "yyMFguWUiU-jyJmqy3kjJdHeGIc,qfcbxfx$iikeeTBk'nwqfEQzovmXxdZnCN-G?z;MAqmx$AO:Mcp'-L;vqBcBsZNd ua;JUiIRY.q\n",
            "k\n",
            "LzborRim'dOwpGrcklt$&&i-xW\n",
            "Y!d\n",
            "3pHt:sfzOp$,vby'I:UAqD&-xwTRCvAGprUjEXI33Zj-nwVsjiyBu&!WYcvb:hOlR&I ?jzBc?mxAvg?WcqNFjNjhQPa\n",
            "\n",
            "Aok ZM,yDYuiqw:dMpW\n",
            "qunjSRNGw3$MeyBvkaSb:aWhSiwFFps.p\n",
            "vFK!Su .QDgd&zWauAyqugm,kr\n",
            "JF!R&noAZ.Ss:.uXo!NPfKrdvErJQFL:Q,s \n",
            "?\n",
            ".KR:SjBeFJNfdmC'$3bHFVYr!cMdXO,ncv lna.DaA.CetN'?3rb&bo?eeaCUjmIimJLq.SvnZX'xrGrN' :M'MnR3qElDRDmgVhk!G\n",
            "TN'sqBYwD3we&J oHeeCJ& CprfnINgzGlpcW' '3:'YLaBa\n",
            "ty!,QCVR!Fxid'DiPSdJZCDzeXBpQYFRodlgFAzxm?$lSO'eqM!uWd,jotfP?MywIiaXbgc\n",
            "b3rVzeMMV3GgqNAovvRldT&,IUSIyrfmkYiXt-ahchsaCGzMqTzlstBX$S3,jx;Yq\n",
            "n.;ZOOVEbRmf,.,S?CCChlXsio:nRLlugp33f\n",
            "ERHqpgJ,PjfqNVA&FT\n",
            "Rkd&,QRTJEA!K-b!eTW;:TaHqXbLgO,Qo?P??LChOCC:NN:L;-thlOX'Qze\n",
            "Ig?WDO\n",
            "-XaoO ExeU'zCa-B-ynr!qFOuE\n",
            "RgwSGO&U3\n",
            "'iFo,zrH\n",
            "VvHdlMq'D&IaAmuxylyPP-H&InAJrUW?fG$&NjAwdl.;;PbqW3dnVA$yDekF??3jGp-UVR!nR!XhRNfNdDyLJvFQJx!LO;a RV;HE?&gbPzSM-cXdMQbXK$K\n",
            "Eo$r RpYOeHmHndph'Hv!WcxS'AeWGE'Dul?t?txIk-herkJrhTon'U wl,?,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUFujPT7Ph0b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}