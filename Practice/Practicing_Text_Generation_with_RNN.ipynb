{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practicing Text Generation with RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNdE7kJymVVv+3s1cJT7QGA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumanyurosha/tensorflow-specialization/blob/master/Practice/Practicing_Text_Generation_with_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kg92iLsQq30"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyI4LFurUINv"
      },
      "source": [
        "# **1. Downloading the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVwPY-h2S3jH",
        "outputId": "f21c5206-d1a4-4b40-898d-8ffa889e2619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "path_to_file = keras.utils.get_file(\"shakespeare.txt\", \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\")\n",
        "\n",
        "text_data = open(path_to_file, mode=\"rb\", ).read().decode(encoding=\"utf-8\")\n",
        "print(\"Characters in dataset : {}\".format(len(text_data)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n",
            "Characters in dataset : 1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzoj0uVTXeu-",
        "outputId": "480cee07-e7ff-4f3a-f0c0-6383d6407562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "print(text_data[:250])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7O7BL8LUNpr"
      },
      "source": [
        "# **2. Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp182CCcTR3N"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "\n",
        "tokenizer.fit_on_texts(text_data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IIZgEskVvqD",
        "outputId": "c2af84eb-bb7c-4c24-eb55-a082ff9ee0cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "for i, item in enumerate(tokenizer.word_index):\n",
        "    print(\"{}: {}\".format(i+1, repr(item)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1: ' '\n",
            "2: 'e'\n",
            "3: 't'\n",
            "4: 'o'\n",
            "5: 'a'\n",
            "6: 'i'\n",
            "7: 'h'\n",
            "8: 's'\n",
            "9: 'r'\n",
            "10: 'n'\n",
            "11: '\\n'\n",
            "12: 'l'\n",
            "13: 'd'\n",
            "14: 'u'\n",
            "15: 'm'\n",
            "16: 'y'\n",
            "17: 'w'\n",
            "18: ','\n",
            "19: 'c'\n",
            "20: 'f'\n",
            "21: 'g'\n",
            "22: 'b'\n",
            "23: 'p'\n",
            "24: ':'\n",
            "25: 'k'\n",
            "26: 'v'\n",
            "27: '.'\n",
            "28: \"'\"\n",
            "29: ';'\n",
            "30: '?'\n",
            "31: '!'\n",
            "32: '-'\n",
            "33: 'j'\n",
            "34: 'q'\n",
            "35: 'x'\n",
            "36: 'z'\n",
            "37: '3'\n",
            "38: '&'\n",
            "39: '$'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5vGI5N8V-9v"
      },
      "source": [
        "max_len = len(tokenizer.word_index)\n",
        "seq_length = 100\n",
        "batch_size = 32\n",
        "vocab_size = max_len\n",
        "embedding_dim = 16"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBczkAC8Ysn1",
        "outputId": "3b740a05-6d07-44bb-cf42-cd6970c1f599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[sequences] = np.array(tokenizer.texts_to_sequences([text_data])) - 1\n",
        "sequences[:5]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([19,  5,  8,  7,  2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaebM3sHQZOp",
        "outputId": "85cd6b29-9ceb-4c7d-f2b0-db9d1b85d98e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = sorted(set(sequences))\n",
        "print(x)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_k3r35fY3IL",
        "outputId": "99c3ab65-0515-422d-f0ad-6e9dad21fc0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(sequences)\n",
        "dataset = dataset.batch(seq_length+1, drop_remainder=True)\n",
        "dataset"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: (101,), types: tf.int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOo2TDfnaBrp"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    output_text = chunk[1:]\n",
        "    return input_text, output_text\n",
        "\n",
        "dataset = dataset.map(split_input_target)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqUbMfF1axeV",
        "outputId": "ec104a32-dfaf-48a1-fc4e-84eb3de334f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "for input_text, output_text in dataset.take(3):\n",
        "    print(tokenizer.sequences_to_texts([input_text.numpy() + 1]))\n",
        "    print(tokenizer.sequences_to_texts([output_text.numpy() + 1]))\n",
        "    print()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['f i r s t   c i t i z e n : \\n b e f o r e   w e   p r o c e e d   a n y   f u r t h e r ,   h e a r   m e   s p e a k . \\n \\n a l l : \\n s p e a k ,   s p e a k . \\n \\n f i r s t   c i t i z e n : \\n y o u']\n",
            "['i r s t   c i t i z e n : \\n b e f o r e   w e   p r o c e e d   a n y   f u r t h e r ,   h e a r   m e   s p e a k . \\n \\n a l l : \\n s p e a k ,   s p e a k . \\n \\n f i r s t   c i t i z e n : \\n y o u  ']\n",
            "\n",
            "['a r e   a l l   r e s o l v e d   r a t h e r   t o   d i e   t h a n   t o   f a m i s h ? \\n \\n a l l : \\n r e s o l v e d .   r e s o l v e d . \\n \\n f i r s t   c i t i z e n : \\n f i r s t ,   y o u  ']\n",
            "['r e   a l l   r e s o l v e d   r a t h e r   t o   d i e   t h a n   t o   f a m i s h ? \\n \\n a l l : \\n r e s o l v e d .   r e s o l v e d . \\n \\n f i r s t   c i t i z e n : \\n f i r s t ,   y o u   k']\n",
            "\n",
            "[\"n o w   c a i u s   m a r c i u s   i s   c h i e f   e n e m y   t o   t h e   p e o p l e . \\n \\n a l l : \\n w e   k n o w ' t ,   w e   k n o w ' t . \\n \\n f i r s t   c i t i z e n : \\n l e t   u s   k\"]\n",
            "[\"o w   c a i u s   m a r c i u s   i s   c h i e f   e n e m y   t o   t h e   p e o p l e . \\n \\n a l l : \\n w e   k n o w ' t ,   w e   k n o w ' t . \\n \\n f i r s t   c i t i z e n : \\n l e t   u s   k i\"]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbsVsTWVcAQX",
        "outputId": "5562260a-06fc-41de-e02c-2c0ce40e0af5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: ((100,), (100,)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-AeMVMEdob4",
        "outputId": "aeb364c1-cc9a-4143-ad5c-8f1f44e627fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((32, 100), (32, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzTXskp0huAt",
        "outputId": "6aa9f0b2-180f-4c1c-f1f3-754c1ca952bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "for input, target in dataset.take(1):\n",
        "    print(input)\n",
        "    print(target)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 8  0  6 ...  2  5  3]\n",
            " [ 5  9  2 ...  5 18  5]\n",
            " [17  0  5 ...  8  1  4]\n",
            " ...\n",
            " [ 0 14  5 ...  4  8  0]\n",
            " [ 4 11  0 ... 25  1  0]\n",
            " [18 11  4 ...  3 12  0]], shape=(32, 100), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[ 0  6  3 ...  5  3  9]\n",
            " [ 9  2  3 ... 18  5  9]\n",
            " [ 0  5  0 ...  1  4  2]\n",
            " ...\n",
            " [14  5  9 ...  8  0 21]\n",
            " [11  0  2 ...  1  0 16]\n",
            " [11  4 13 ... 12  0  5]], shape=(32, 100), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EafFfrz7fAmo"
      },
      "source": [
        "# **Creating a Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eoGb7fXd0cC"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "    keras.layers.LSTM(128, return_sequences=True),\n",
        "    keras.layers.LSTM(64, return_sequences=True),\n",
        "    keras.layers.Dense(vocab_size)\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qU0xXR9NBo-",
        "outputId": "7bd07631-ce2c-495b-ff55-90afd1ff4bb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (32, None, 16)            624       \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (32, None, 128)           74240     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (32, None, 64)            49408     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (32, None, 39)            2535      \n",
            "=================================================================\n",
            "Total params: 126,807\n",
            "Trainable params: 126,807\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f5MmkUJOqc_",
        "outputId": "e4db2b6a-02f2-410a-f13a-f2e5cc43fcc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for input_example, output_example in dataset.take(1):\n",
        "    predicted_example = model(input_example)\n",
        "\n",
        "print(predicted_example.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 100, 39)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L25oF4cGMqPy",
        "outputId": "8860bac2-05c6-4205-9cf6-75277d8ace78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "model.fit(dataset, epochs=20)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 3.8757\n",
            "Epoch 2/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 3.1775\n",
            "Epoch 3/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.9341\n",
            "Epoch 4/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.8558\n",
            "Epoch 5/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.7546\n",
            "Epoch 6/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.6825\n",
            "Epoch 7/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.6151\n",
            "Epoch 8/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.6336\n",
            "Epoch 9/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.7295\n",
            "Epoch 10/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.7535\n",
            "Epoch 11/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.6746\n",
            "Epoch 12/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.6894\n",
            "Epoch 13/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.7355\n",
            "Epoch 14/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.7338\n",
            "Epoch 15/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.6430\n",
            "Epoch 16/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.6168\n",
            "Epoch 17/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.6079\n",
            "Epoch 18/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.5821\n",
            "Epoch 19/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.7903\n",
            "Epoch 20/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.7106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3e18e37ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUr0VxstMyTc",
        "outputId": "2d550907-80f9-4aec-de63-9f9afa5c1f1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=seq_length),\n",
        "    keras.layers.LSTM(128, return_sequences=True),\n",
        "    keras.layers.LSTM(64, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(vocab_size,\n",
        "                                                    activation=\"softmax\"))\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 100, 16)           624       \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 100, 128)          74240     \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 100, 64)           49408     \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 100, 39)           2535      \n",
            "=================================================================\n",
            "Total params: 126,807\n",
            "Trainable params: 126,807\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfYlxBiHR_0g",
        "outputId": "20f72418-d3bd-413b-e211-1d9fba08d71d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "model.fit(dataset, epochs=20)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "345/345 [==============================] - 4s 12ms/step - loss: 3.0542\n",
            "Epoch 2/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.4515\n",
            "Epoch 3/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.2848\n",
            "Epoch 4/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.1939\n",
            "Epoch 5/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.1223\n",
            "Epoch 6/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.0600\n",
            "Epoch 7/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.0068\n",
            "Epoch 8/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 1.9599\n",
            "Epoch 9/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 1.9177\n",
            "Epoch 10/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 1.8801\n",
            "Epoch 11/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 1.8445\n",
            "Epoch 12/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 1.8123\n",
            "Epoch 13/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 1.7832\n",
            "Epoch 14/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 1.7563\n",
            "Epoch 15/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 1.7314\n",
            "Epoch 16/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 1.7092\n",
            "Epoch 17/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 1.6885\n",
            "Epoch 18/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 1.6692\n",
            "Epoch 19/20\n",
            "345/345 [==============================] - 4s 12ms/step - loss: 1.6521\n",
            "Epoch 20/20\n",
            "345/345 [==============================] - 4s 12ms/step - loss: 1.6361\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3e18135a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1brsFu7aSDJg",
        "outputId": "12a92f7a-58a3-4482-c0ca-6071b0a6d15f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True),\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(vocab_size,\n",
        "                                                    activation=\"softmax\"))\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "model.fit(dataset, epochs=20)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 2.6522\n",
            "Epoch 2/20\n",
            "345/345 [==============================] - 4s 10ms/step - loss: 2.0617\n",
            "Epoch 3/20\n",
            "345/345 [==============================] - 4s 10ms/step - loss: 1.8556\n",
            "Epoch 4/20\n",
            "345/345 [==============================] - 4s 10ms/step - loss: 1.7355\n",
            "Epoch 5/20\n",
            "345/345 [==============================] - 4s 10ms/step - loss: 1.6590\n",
            "Epoch 6/20\n",
            "345/345 [==============================] - 4s 10ms/step - loss: 1.6066\n",
            "Epoch 7/20\n",
            "345/345 [==============================] - 4s 10ms/step - loss: 1.5684\n",
            "Epoch 8/20\n",
            "345/345 [==============================] - 4s 10ms/step - loss: 1.5399\n",
            "Epoch 9/20\n",
            "345/345 [==============================] - 4s 10ms/step - loss: 1.5169\n",
            "Epoch 10/20\n",
            "345/345 [==============================] - 4s 10ms/step - loss: 1.4978\n",
            "Epoch 11/20\n",
            "345/345 [==============================] - 4s 10ms/step - loss: 1.4824\n",
            "Epoch 12/20\n",
            "345/345 [==============================] - 4s 10ms/step - loss: 1.4690\n",
            "Epoch 13/20\n",
            "345/345 [==============================] - 4s 10ms/step - loss: 1.4583\n",
            "Epoch 14/20\n",
            "345/345 [==============================] - 4s 10ms/step - loss: 1.4476\n",
            "Epoch 15/20\n",
            "345/345 [==============================] - 4s 10ms/step - loss: 1.4387\n",
            "Epoch 16/20\n",
            "345/345 [==============================] - 4s 10ms/step - loss: 1.4304\n",
            "Epoch 17/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 1.4226\n",
            "Epoch 18/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 1.4165\n",
            "Epoch 19/20\n",
            "345/345 [==============================] - 4s 11ms/step - loss: 1.4097\n",
            "Epoch 20/20\n",
            "345/345 [==============================] - 4s 10ms/step - loss: 1.4042\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3de48f34e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1MgliDba8SC",
        "outputId": "4793dd1f-5750-459a-eecc-f93a2d7cabc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for input_example, output_example in dataset.take(1):\n",
        "    predicted_example = model(input_example)\n",
        "\n",
        "print(predicted_example.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 100, 39)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VVNbEsOa-Ed",
        "outputId": "db69beb7-ce5a-4410-cd7a-bd31bc098398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "prediction = tf.random.categorical(predicted_example[0], num_samples=1)\n",
        "prediction = tf.squeeze(prediction, axis=-1)\n",
        "prediction"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
              "array([24, 12, 19,  5,  4,  2, 26,  3,  7, 25,  4,  8,  6, 31, 17, 17, 26,\n",
              "       23,  8, 20,  1, 13, 11, 27, 24, 13,  3,  8, 17, 34, 36, 24, 17,  0,\n",
              "       24, 22,  2, 11, 38, 17, 28,  4, 14, 14, 28,  4,  3, 23, 33, 38, 34,\n",
              "        7, 10, 21,  8,  0, 16, 14, 11, 12, 38, 34, 32, 17, 14, 30, 27, 11,\n",
              "       20,  2, 17, 21, 19, 36, 17, 19, 28, 10,  8, 26, 20, 21, 31,  2,  5,\n",
              "        9, 35, 30,  8, 10, 38,  1,  9,  9, 23, 35, 13, 32,  3,  0])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mi-00YVbl18",
        "outputId": "3223b925-ae06-4ae5-f5c2-016d3e8deac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "[prediction] = tokenizer.sequences_to_texts([prediction.numpy() + 1])\n",
        "print(prediction)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k d f i a t . o s v a r h - , , . : r g e u l ' k u o r , x 3 k ,   k p t l $ , ; a m m ; a o : q $ x s \n",
            " b r   w m l d $ x j , m ! ' l g t , b f 3 , f ; \n",
            " r . g b - t i n z ! r \n",
            " $ e n n : z u j o  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7rVyQgnTbMB"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "\n",
        "    # number of characters to generate\n",
        "    text_length = 1000\n",
        "\n",
        "    # vectorize the start_string\n",
        "    input_sequence = np.array(tokenizer.texts_to_sequences([start_string])) - 1\n",
        "\n",
        "    text_generated = []\n",
        "    # some comment related to temparature\n",
        "    temparature = 1.0\n",
        "\n",
        "    for i in range(text_length):\n",
        "        predictions = model(input_sequence)\n",
        "        # removing the batch dimension since the batch size == 1\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0]\n",
        "\n",
        "        input_sequence = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        [generated] = tokenizer.sequences_to_texts([predicted_id.numpy() + 1])\n",
        "        text_generated.append(generated)\n",
        "\n",
        "        return (start_string + \"\".join(text_generated))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5xme4Xha3WJ",
        "outputId": "e4aea70e-6c82-479d-d813-ddc38c086df1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(generate_text(model, u\"ROMEO: \"))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-9cf743252bd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"ROMEO: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-61-503835861f6f>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(model, start_string)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# removing the batch dimension since the batch size == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    370\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \"\"\"\n\u001b[1;32m    385\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 386\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m       last_output, outputs, runtime, states = self._defun_gru_call(\n\u001b[0;32m--> 441\u001b[0;31m           inputs, initial_state, training, mask, row_lengths)\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36m_defun_gru_call\u001b[0;34m(self, inputs, initial_state, training, mask, sequence_lengths)\u001b[0m\n\u001b[1;32m    494\u001b[0m       \u001b[0;31m# Under eager context, check the device placement and prefer the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcan_use_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mgpu_gru_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnormal_gru_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mgpu_gru\u001b[0;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths)\u001b[0m\n\u001b[1;32m    654\u001b[0m     outputs, h, _, _ = gen_cudnn_rnn_ops.cudnn_rnn(\n\u001b[1;32m    655\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_h\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_c\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m         rnn_mode='gru')\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   \u001b[0mlast_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\u001b[0m in \u001b[0;36mcudnn_rnn\u001b[0;34m(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name)\u001b[0m\n\u001b[1;32m    101\u001b[0m           \u001b[0minput_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m           \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m           ctx=_ctx)\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\u001b[0m in \u001b[0;36mcudnn_rnn_eager_fallback\u001b[0;34m(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name, ctx)\u001b[0m\n\u001b[1;32m    178\u001b[0m   \"is_training\", is_training)\n\u001b[1;32m    179\u001b[0m   _result = _execute.execute(b\"CudnnRNN\", 4, inputs=_inputs_flat,\n\u001b[0;32m--> 180\u001b[0;31m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m    181\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     _execute.record_gradient(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Invalid input_h shape: [1,32,128] [1,1,128] [Op:CudnnRNN]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtOpLFPIfJBE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}