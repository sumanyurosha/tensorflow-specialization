{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practicing Text Generation with RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMBNt8/NED+i9UupmNRi344",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumanyurosha/tensorflow-specialization/blob/master/Practicing_Text_Generation_with_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kg92iLsQq30"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyI4LFurUINv"
      },
      "source": [
        "# **1. Downloading the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVwPY-h2S3jH",
        "outputId": "3534e53c-36b8-4d0d-dfa2-a4551602d323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path_to_file = keras.utils.get_file(\"shakespeare.txt\", \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\")\n",
        "\n",
        "text_data = open(path_to_file, mode=\"rb\", ).read().decode(encoding=\"utf-8\")\n",
        "print(\"Characters in dataset : {}\".format(len(text_data)))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Characters in dataset : 1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzoj0uVTXeu-",
        "outputId": "1aa8e064-6cff-4e2b-c501-6abb5daae5fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "print(text_data[:250])"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7O7BL8LUNpr"
      },
      "source": [
        "# **2. Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp182CCcTR3N",
        "outputId": "6158c013-dd39-4a31-9b95-e28c07738759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab = sorted(set(text_data))\n",
        "print(\"There are {} unique characters in text\".format(len(vocab)))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 65 unique characters in text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IIZgEskVvqD",
        "outputId": "f668a41e-8a41-44dd-b58a-6a85c1eb4e5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text_data])\n",
        "print(text_as_int[:5])"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18 47 56 57 58]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI9L0ExKilV0",
        "outputId": "34167069-40ec-46f2-b291-ce0564a658c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "for char, _ in zip(char2idx, range(20)):\n",
        "    print(\"{}: {}\".format(repr(char), char2idx[char]))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'\\n': 0\n",
            "' ': 1\n",
            "'!': 2\n",
            "'$': 3\n",
            "'&': 4\n",
            "\"'\": 5\n",
            "',': 6\n",
            "'-': 7\n",
            "'.': 8\n",
            "'3': 9\n",
            "':': 10\n",
            "';': 11\n",
            "'?': 12\n",
            "'A': 13\n",
            "'B': 14\n",
            "'C': 15\n",
            "'D': 16\n",
            "'E': 17\n",
            "'F': 18\n",
            "'G': 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXsfB04ai7cj",
        "outputId": "927ccc73-e434-46d2-817a-833cb8dbf0f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(text_data[:13])\n",
        "print(text_as_int[:13])"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen\n",
            "[18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5vGI5N8V-9v"
      },
      "source": [
        "seq_length = 100\n",
        "batch_size = 64\n",
        "vocab_size = len(char2idx)\n",
        "embedding_dim = 256"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_k3r35fY3IL",
        "outputId": "68d7f128-66fa-4d10-e581-ff089c8c9ad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "dataset = dataset.batch(seq_length+1, drop_remainder=True)\n",
        "dataset"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: (101,), types: tf.int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOo2TDfnaBrp"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    output_text = chunk[1:]\n",
        "    return input_text, output_text\n",
        "\n",
        "dataset = dataset.map(split_input_target)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqUbMfF1axeV",
        "outputId": "7b94819a-7fd7-4b9e-b2e3-c722af7626f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "for input_text, output_text in dataset.take(3):\n",
        "    print(repr(\"\".join([idx2char[c] for c in input_text])))\n",
        "    print(repr(\"\".join([idx2char[c] for c in output_text])))\n",
        "    print()"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "\n",
            "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you '\n",
            "'re all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "\n",
            "\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us k\"\n",
            "\"ow Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbsVsTWVcAQX",
        "outputId": "e47b8f7c-9529-4c8b-e8b4-82182a72f02e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: ((100,), (100,)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-AeMVMEdob4",
        "outputId": "4dc8308a-58ed-4b22-e79a-d41d3078d432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzTXskp0huAt",
        "outputId": "db214fb9-d78c-44d5-b1fc-e9e6e56280be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "for input, target in dataset.take(1):\n",
        "    print(input)\n",
        "    print(target)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[58 46 63 ... 53 59 50]\n",
            " [53 49  1 ...  0  0 16]\n",
            " [49  1 63 ...  1 53 59]\n",
            " ...\n",
            " [51 43 56 ... 59 52 42]\n",
            " [ 0 17 52 ...  1 58 46]\n",
            " [21 26 21 ...  1 44 53]], shape=(64, 100), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[46 63  1 ... 59 50 42]\n",
            " [49  1 53 ...  0 16 33]\n",
            " [ 1 63 53 ... 53 59 58]\n",
            " ...\n",
            " [43 56  1 ... 52 42 11]\n",
            " [17 52 44 ... 58 46 43]\n",
            " [26 21 33 ... 44 53 56]], shape=(64, 100), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EafFfrz7fAmo"
      },
      "source": [
        "# **Creating a Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWTXW4e2qy1z"
      },
      "source": [
        "def loss(labels, logits):\n",
        "    return keras.losses.sparse_categorical_crossentropy( labels, logits,\n",
        "                                                        from_logits=True,)\n"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwmDIFVJm7Qe"
      },
      "source": [
        "def build_model(batch_size, rnn_units):\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                               batch_input_shape=[batch_size, None]),\n",
        "        keras.layers.GRU(rnn_units, return_sequences=True,\n",
        "                         stateful=True,\n",
        "                         recurrent_initializer=\"glorot_uniform\"),\n",
        "        keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxfrs2_dpOWp"
      },
      "source": [
        "checkpoint_dir = \"/checkpoints\"\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = keras.callbacks.ModelCheckpoint(checkpoint_prefix, \n",
        "                                             save_weights_only=True)"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY6R9O6ikjbR",
        "outputId": "c68866e1-998e-421f-df03-41395a87af79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for input_example, output_example in dataset.take(1):\n",
        "    predicted_example = model(input_example)\n",
        "\n",
        "print(predicted_example.shape)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 65)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU3_fbhtk42u",
        "outputId": "4d61b7bc-7eb6-445b-9a2a-f8d552882f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model = build_model(batch_size=batch_size, rnn_units=1024)\n",
        "model.compile(loss=loss, optimizer=\"adam\")\n",
        "model.summary()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_14 (Embedding)     (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "gru_14 (GRU)                 (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3QaxU6fn1wh",
        "outputId": "b48d91f8-a43d-4f0a-b5e5-67e797439795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model.fit(dataset, epochs=30, callbacks=[checkpoint_callback], verbose=1)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "172/172 [==============================] - 10s 57ms/step - loss: 2.6601\n",
            "Epoch 2/30\n",
            "172/172 [==============================] - 10s 60ms/step - loss: 1.9612\n",
            "Epoch 3/30\n",
            "172/172 [==============================] - 10s 61ms/step - loss: 1.6950\n",
            "Epoch 4/30\n",
            "172/172 [==============================] - 10s 60ms/step - loss: 1.5469\n",
            "Epoch 5/30\n",
            "172/172 [==============================] - 10s 60ms/step - loss: 1.4578\n",
            "Epoch 6/30\n",
            "172/172 [==============================] - 10s 58ms/step - loss: 1.3971\n",
            "Epoch 7/30\n",
            "172/172 [==============================] - 10s 58ms/step - loss: 1.3499\n",
            "Epoch 8/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 1.3123\n",
            "Epoch 9/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 1.2773\n",
            "Epoch 10/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 1.2436\n",
            "Epoch 11/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 1.2126\n",
            "Epoch 12/30\n",
            "172/172 [==============================] - 10s 60ms/step - loss: 1.1796\n",
            "Epoch 13/30\n",
            "172/172 [==============================] - 10s 60ms/step - loss: 1.1477\n",
            "Epoch 14/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 1.1134\n",
            "Epoch 15/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 1.0804\n",
            "Epoch 16/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 1.0445\n",
            "Epoch 17/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 1.0098\n",
            "Epoch 18/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 0.9724\n",
            "Epoch 19/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 0.9376\n",
            "Epoch 20/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 0.9036\n",
            "Epoch 21/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 0.8711\n",
            "Epoch 22/30\n",
            "172/172 [==============================] - 10s 60ms/step - loss: 0.8416\n",
            "Epoch 23/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 0.8141\n",
            "Epoch 24/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 0.7906\n",
            "Epoch 25/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 0.7685\n",
            "Epoch 26/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 0.7502\n",
            "Epoch 27/30\n",
            "172/172 [==============================] - 10s 58ms/step - loss: 0.7322\n",
            "Epoch 28/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 0.7178\n",
            "Epoch 29/30\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 0.7050\n",
            "Epoch 30/30\n",
            "172/172 [==============================] - 10s 58ms/step - loss: 0.6923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fde2da59a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f5MmkUJOqc_",
        "outputId": "c3ca6d21-fcc4-4744-9957-b9e826a1bd55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for input_example, output_example in dataset.take(1):\n",
        "    predicted_example = model(input_example)\n",
        "\n",
        "print(predicted_example.shape)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 65)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VVNbEsOa-Ed",
        "outputId": "7f1b2fad-179d-4217-b558-265b74f6ca60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "prediction = tf.random.categorical(predicted_example[0], num_samples=1)\n",
        "prediction = tf.squeeze(prediction, axis=-1)\n",
        "prediction"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
              "array([ 1, 58, 52,  1, 53, 43, 57, 41, 53, 52, 53, 59, 56,  1, 42,  1, 63,\n",
              "       63,  1, 58,  1, 41, 39, 52,  1, 41, 43, 47, 50, 46,  1, 45, 50, 43,\n",
              "       56,  1, 33, 50, 53, 44, 43, 57, 57,  5, 42,  1, 58, 53,  1, 46, 39,\n",
              "       51,  6,  1, 61, 46, 43,  1,  1,  5, 43, 57,  1, 39, 43, 54, 43, 56,\n",
              "       45, 43, 57,  1, 61, 59, 57, 58,  0, 21, 52,  1, 40, 46, 43, 58,  1,\n",
              "       46, 53, 50, 39, 39, 42, 43,  6, 40, 53, 56, 43,  1, 40, 47])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mi-00YVbl18",
        "outputId": "5971f2c0-cd28-4ca6-8f43-601726d399c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "prediction = \"\".join([idx2char[idx] for idx in prediction])\n",
        "print(prediction)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " tn oesconour d yy t can ceilh gler Ulofess'd to ham, whe  'es aeperges wust\n",
            "In bhet holaade,bore bi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD-1V6ZT0niu",
        "outputId": "d1424348-3bee-4f1c-e05a-de3d076f6812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/checkpoints/ckpt_30'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsVqpJJ6p8_X",
        "outputId": "74d1fde8-0f2b-4b8d-dc1a-0d3cd4ccac4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = build_model(batch_size=1, rnn_units=1024)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fddf82e6a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k78u1ciz90o",
        "outputId": "9664cba3-10cb-4930-8909-12649b123cdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_16 (Embedding)     (1, None, 256)            16640     \n",
            "_________________________________________________________________\n",
            "gru_16 (GRU)                 (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (1, None, 65)             66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7rVyQgnTbMB"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "\n",
        "    # number of characters to generate\n",
        "    text_length = 1000\n",
        "\n",
        "    # vectorize the start_string\n",
        "    input_sequence = [char2idx[c] for c in start_string]\n",
        "    input_sequence = tf.expand_dims(input_sequence, 0)\n",
        "\n",
        "    text_generated = []\n",
        "    # some comment related to temparature\n",
        "    temparature = 1.0\n",
        "\n",
        "    model.reset_states()\n",
        "    for i in range(text_length):\n",
        "        predictions = model(input_sequence)\n",
        "\n",
        "        # removing the batch dimension since the batch size == 1\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # taking out the last predicted character in the output sequence\n",
        "        predicted_id = tf.random.categorical( predictions, num_samples=1)[-1,0].numpy()\n",
        "        \n",
        "        input_sequence = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])    \n",
        "\n",
        "    return (start_string + \"\".join(text_generated))"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5xme4Xha3WJ",
        "outputId": "a37e214b-8853-4f10-cadb-abe5fef0eaa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "print(generate_text(model, u\"ROMEO: \"))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO: I say not to bring the king\n",
            "Is wise another ancertaring: cracks the proud cease.\n",
            "Being boxemed, the most get your brothers both;\n",
            "Without your patience, to myself; for that I were she\n",
            "standing my way, I say. I have seen.\n",
            "\n",
            "SEBASTIAN:\n",
            "Ay, a thousand lives and the hand were broke.\n",
            "Your mother, would he fear us none so well at once;' any\n",
            "'Tis he at your house they be diered at once than gone:\n",
            "And when I do now, I pray you.\n",
            "\n",
            "Fetch all floods; id\n",
            "hath power to crush. Nay, they are rising,\n",
            "For he did bear my country's face.\n",
            "HatHARD IV:\n",
            "Take the usly, and every thing about thee; therein desire\n",
            "It is my wife, that once he perceives the body,\n",
            "For stone together to our arrival froward,\n",
            "As is the hand, though Marcius is proud;\n",
            "And in the hand of death!\n",
            "Look, and bleased, say these must be colighbe,\n",
            "And wretched me brother, the rinds are husbany:\n",
            "Since you, my noble cousix to the queen,\n",
            "Devouring our readiness in revivered.\n",
            "\n",
            "Second Murderer:\n",
            "A matter, none, but of and waiting, who\n",
            "Do girth, and good\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtOpLFPIfJBE"
      },
      "source": [
        ""
      ],
      "execution_count": 112,
      "outputs": []
    }
  ]
}